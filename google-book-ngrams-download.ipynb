{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65d5f03-ebba-424c-a452-8b5351c017f6",
   "metadata": {},
   "source": [
    "The \"Google Million\". All are in English with dates ranging from 1500 to 2008. No more than about 6000 books were chosen from any one year, which means that all of the scanned books from early years are present, and books from later years are randomly sampled. The random samplings reflect the subject distributions for the year (so there are more computer books in 2000 than 1980).\n",
    "\n",
    "- https://books.google.com/ngrams/info\n",
    "- https://storage.googleapis.com/books/ngrams/books/datasetsv2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976eb9e-6f92-4330-919e-f920f094db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter out older years, group by ngram and sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70476313-018b-49af-84f8-7682e6d84468",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815fd56f-da9d-4dc1-9e96-7de03771a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    file = f'googlebooks-eng-1M-2gram-20090715-{i}.csv.zip'\n",
    "    url = f'http://storage.googleapis.com/books/ngrams/books/{file}'\n",
    "    response = rq.get(url)\n",
    "    with open(f'ngrams/{file}', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f40e6609-2c15-4a88-b983-de8d29e2d925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a757663455794865885bc519821f66ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    file = f'googlebooks-eng-1M-2gram-20090715-{i}.csv.zip'\n",
    "    try:\n",
    "        df = pd.read_csv(f'ngrams/{file}', sep='\\t')\n",
    "    except Exception:\n",
    "        continue\n",
    "    df.columns =['ngram', 'year', 'occurrences', 'pages', 'books']\n",
    "    df = df[\n",
    "        df.year.ge(2000)\n",
    "        & ~df.ngram.str.contains(f'[^{string.ascii_letters + \" \"}]+')\n",
    "    ].groupby('ngram').occurrences.sum()\n",
    "    df.to_csv(f\"ngrams/{file.replace('.csv.zip', '-clean.csv.gz')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75578c-c353-4152-a82e-e4e718a27a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
